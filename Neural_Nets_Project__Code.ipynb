{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQZSfizfopRm"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i8WZJ3FyopRo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# from scipy.ndimage import imread, imresize\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize as imresize\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAes0h5OopRp"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # !pip install tensorflow==2.8.0\n",
        "# import keras\n",
        "# print(keras.__version__)"
      ],
      "metadata": {
        "id": "F9NWA6iKTlpF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uL3J5u5GopRp"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTHGXttGopRq"
      },
      "source": [
        "1. read the folder names for training and validation.\n",
        "2. set the `batch_size` here such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5UwAIbY1q5G",
        "outputId": "dc738725-6a5e-4cde-a970-cf464f577d65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gP6bgNcWopRq"
      },
      "outputs": [],
      "source": [
        "train_doc = np.random.permutation(open('/content/drive/MyDrive/Colab Notebooks/gesture_recognition/Project_data/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/drive/MyDrive/Colab Notebooks/gesture_recognition/Project_data/val.csv').readlines())\n",
        "batch_size = 51"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3BrTuiiopRq"
      },
      "source": [
        "## Generator\n",
        "1. preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames.\n",
        "2. experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r7W1w1HBopRr"
      },
      "outputs": [],
      "source": [
        "def generator(source_path, folder_list, batch_size):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    img_idx = [11,12,13,14,15,16,17,18,19,20,21,22,23,24,25] #create a list of image numbers you want to use for a particular video\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(source_path)/batch_size) # calculate the number of batches\n",
        "        # print('num_batch', num_batches)\n",
        "        # print(len(source_path))\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,15,100,100,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                # print(\"folder_name\", t[folder + (batch*batch_size)].split(';')[0])\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    # print('source_path',source_path, '  folder', folder, ' batch', batch, 'bactch size',batch_size)\n",
        "                    # print(\"len of img\", len(imgs), \"item:\", item)\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "                    image.resize(100,100)\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] /= 255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,1] /= 255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] /= 255 #normalise and feed in the image\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n",
        "\n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        if((len(source_path)%batch_size)//2==0):\n",
        "            batch_size = 2\n",
        "        else:\n",
        "            batch_size = 1\n",
        "        num_batches = len(source_path)%batch_size # calculate the number of batches\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            batch_data = np.zeros((batch_size,15,100,100,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "            for folder in range(batch_size): # iterate over the batch_size\n",
        "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "                    # Cropped image of above dimension\n",
        "                    # (It will not change orginal image)\n",
        "\n",
        "                    #image = image.crop((0, 0, 120, 120))\n",
        "                    image = image.resize(100, 100)\n",
        "\n",
        "\n",
        "                    #crop the images and resize them. Note that the images are of 2 different shape\n",
        "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "\n",
        "                    batch_data[folder,idx,:,:,0] /= 255\n",
        "                    batch_data[folder,idx,:,:,1] /= 255 #normalise and feed in the image\n",
        "                    batch_data[folder,idx,:,:,2] /= 255 #normalise and feed in the image\n",
        "\n",
        "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3lb1FinopRr"
      },
      "source": [
        "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8fc9OhXopRr",
        "outputId": "14525d8e-877c-4a78-bcd2-6231120638d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 15\n"
          ]
        }
      ],
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/gesture_recognition/Project_data/train'\n",
        "val_path = '/content/drive/MyDrive/Colab Notebooks/gesture_recognition/Project_data/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 15\n",
        "print ('# epochs =', num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_path)"
      ],
      "metadata": {
        "id": "s98cv4Xskus4",
        "outputId": "78ba2472-43f2-4505-baab-cb1a0d3ffd51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj1ZWEUEopRs"
      },
      "source": [
        "## Model\n",
        "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MjoagrP9opRs"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
        "from keras.layers import Conv3D, MaxPooling3D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n",
        "Input_shape = (15,100,100,3)\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, (3,3,3), padding='same',input_shape=Input_shape))\n",
        "#model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=sample_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv3D(32, (3, 3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv3D(64, (3, 3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQjCEN1opRs"
      },
      "source": [
        "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq-a_bjvopRs",
        "outputId": "10eddb0e-8acb-4351-fbb4-c4111eb4c017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 15, 100, 100, 32   2624      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 15, 100, 100, 32   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 15, 100, 100, 32   128       \n",
            " Normalization)              )                                   \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 13, 98, 98, 32)    27680     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 13, 98, 98, 32)    0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 13, 98, 98, 32)    128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 6, 49, 49, 32)     0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6, 49, 49, 32)     0         \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 6, 49, 49, 64)     55360     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6, 49, 49, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 6, 49, 49, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_3 (Conv3D)           (None, 4, 47, 47, 64)     110656    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4, 47, 47, 64)     0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 4, 47, 47, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 2, 23, 23, 64)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2, 23, 23, 64)     0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 67712)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               34669056  \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34868709 (133.01 MB)\n",
            "Trainable params: 34868325 (133.01 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "optimiser = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyF7GCqGopRs"
      },
      "source": [
        "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iYKz6tmqopRt"
      },
      "outputs": [],
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SvUIIjO7opRt"
      },
      "outputs": [],
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "# filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "filepath = model_name + 'model-epoch{epoch:05d}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto') #, save_freq=1\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 10,\n",
        "  verbose = 0, mode = \"auto\", min_delta = 1e-04, cooldown = 0,\n",
        "  min_lr = 0)\n",
        "callbacks_list = [checkpoint, LR]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANZdEi1BopRt"
      },
      "source": [
        "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1oBsNYVfopRt"
      },
      "outputs": [],
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM0sQmEwiHPk",
        "outputId": "a407ba29-99bb-4387-aa97-0082503dd11e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "663"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP1kQ02yopRt"
      },
      "source": [
        "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kMx-Tugfru3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-IUfIfwopRt"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKSQiOJx3FsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model CONV2D + LSTM"
      ],
      "metadata": {
        "id": "fg9Zpr_DG-Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #write your model here\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, ConvLSTM2D\n",
        "\n",
        "\n",
        "\n",
        "# Input_shape_1 = (18, 100, 100, 3)\n",
        "# model = Sequential()\n",
        "# model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same'), input_shape=Input_shape_1))\n",
        "# model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=\"he_normal\", activation='relu')))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "# model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "# model.add(TimeDistributed(Dropout(0.5)))\n",
        "\n",
        "# model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "# model.add(TimeDistributed(Dropout(0.5)))\n",
        "\n",
        "# model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "# model.add(TimeDistributed(Dropout(0.5)))\n",
        "\n",
        "# model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(Conv2D(512, (3,3), padding='same', activation='relu')))\n",
        "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "# model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(LSTM(512, return_sequences=False, dropout=0.5))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "75QnMCRdHAcu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input_shape = (15,100,100,3)\n",
        "# model = Sequential()\n",
        "# model.add(TimeDistributed(\n",
        "#     Conv2D(8, (3,3), activation='relu'), input_shape=Input_shape)\n",
        "# )\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(TimeDistributed(\n",
        "#     Conv2D(16, (3,3), activation='relu'))\n",
        "# )\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(\n",
        "#     ConvLSTM2D(8, kernel_size = 3, return_sequences=False)\n",
        "# )\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(TimeDistributed(\n",
        "#     Dense(64, activation='relu'))\n",
        "# )\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(GlobalAveragePooling2D())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "q_SqvlGndzLD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #write your model here\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, ConvLSTM2D\n",
        "\n",
        "\n",
        "\n",
        "Input_shape_1 = (18, 100, 100, 3)\n",
        "model = Sequential()\n",
        "\n",
        "# Adding BatchNormalization and Dropout after Activation\n",
        "model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2), padding='same'), input_shape=Input_shape_1))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(Conv2D(32, (3,3), kernel_initializer=\"he_normal\")))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "model.add(TimeDistributed(Dropout(0.25)))\n",
        "\n",
        "model.add(TimeDistributed(Conv2D(64, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(Conv2D(64, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "model.add(TimeDistributed(Dropout(0.25)))\n",
        "\n",
        "model.add(TimeDistributed(Conv2D(128, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(Conv2D(128, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "model.add(TimeDistributed(Dropout(0.25)))\n",
        "\n",
        "model.add(TimeDistributed(Conv2D(256, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(Conv2D(256, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "model.add(TimeDistributed(Dropout(0.25)))\n",
        "\n",
        "model.add(TimeDistributed(Conv2D(512, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(Conv2D(512, (3,3), padding='same')))\n",
        "model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(Activation('relu')))\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "model.add(TimeDistributed(Dropout(0.25)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(512, return_sequences=False, dropout=0.5))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wJ_pb4tN8JV",
        "outputId": "c6a77f5a-456a-437a-a636-d4da8ee580ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_3 (TimeDi  (None, 18, 50, 50, 32)    4736      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDi  (None, 18, 50, 50, 32)    128       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDi  (None, 18, 50, 50, 32)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDi  (None, 18, 48, 48, 32)    9248      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDi  (None, 18, 48, 48, 32)    128       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDi  (None, 18, 48, 48, 32)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDi  (None, 18, 24, 24, 32)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_10 (TimeD  (None, 18, 24, 24, 32)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_11 (TimeD  (None, 18, 24, 24, 64)    18496     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_12 (TimeD  (None, 18, 24, 24, 64)    256       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_13 (TimeD  (None, 18, 24, 24, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_14 (TimeD  (None, 18, 24, 24, 64)    36928     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_15 (TimeD  (None, 18, 24, 24, 64)    256       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_16 (TimeD  (None, 18, 24, 24, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_17 (TimeD  (None, 18, 12, 12, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_18 (TimeD  (None, 18, 12, 12, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_19 (TimeD  (None, 18, 12, 12, 128)   73856     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_20 (TimeD  (None, 18, 12, 12, 128)   512       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_21 (TimeD  (None, 18, 12, 12, 128)   0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_22 (TimeD  (None, 18, 12, 12, 128)   147584    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_23 (TimeD  (None, 18, 12, 12, 128)   512       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_24 (TimeD  (None, 18, 12, 12, 128)   0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_25 (TimeD  (None, 18, 6, 6, 128)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_26 (TimeD  (None, 18, 6, 6, 128)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_27 (TimeD  (None, 18, 6, 6, 256)     295168    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_28 (TimeD  (None, 18, 6, 6, 256)     1024      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_29 (TimeD  (None, 18, 6, 6, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_30 (TimeD  (None, 18, 6, 6, 256)     590080    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_31 (TimeD  (None, 18, 6, 6, 256)     1024      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_32 (TimeD  (None, 18, 6, 6, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_33 (TimeD  (None, 18, 3, 3, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_34 (TimeD  (None, 18, 3, 3, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_35 (TimeD  (None, 18, 3, 3, 512)     1180160   \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_36 (TimeD  (None, 18, 3, 3, 512)     2048      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_37 (TimeD  (None, 18, 3, 3, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_38 (TimeD  (None, 18, 3, 3, 512)     2359808   \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_39 (TimeD  (None, 18, 3, 3, 512)     2048      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_40 (TimeD  (None, 18, 3, 3, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_41 (TimeD  (None, 18, 1, 1, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_42 (TimeD  (None, 18, 1, 1, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_43 (TimeD  (None, 18, 512)           0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 18, 512)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512)               2099200   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6825765 (26.04 MB)\n",
            "Trainable params: 6821797 (26.02 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.optimizers.Adam(lr=0.001)\n",
        "optimiser = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print (model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPw0K6qbHLH2",
        "outputId": "4ce56fcd-3533-4971-ad72-c9b7666e5536"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed_3 (TimeDi  (None, 18, 50, 50, 32)    4736      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDi  (None, 18, 50, 50, 32)    128       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDi  (None, 18, 50, 50, 32)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDi  (None, 18, 48, 48, 32)    9248      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDi  (None, 18, 48, 48, 32)    128       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDi  (None, 18, 48, 48, 32)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDi  (None, 18, 24, 24, 32)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_10 (TimeD  (None, 18, 24, 24, 32)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_11 (TimeD  (None, 18, 24, 24, 64)    18496     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_12 (TimeD  (None, 18, 24, 24, 64)    256       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_13 (TimeD  (None, 18, 24, 24, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_14 (TimeD  (None, 18, 24, 24, 64)    36928     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_15 (TimeD  (None, 18, 24, 24, 64)    256       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_16 (TimeD  (None, 18, 24, 24, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_17 (TimeD  (None, 18, 12, 12, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_18 (TimeD  (None, 18, 12, 12, 64)    0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_19 (TimeD  (None, 18, 12, 12, 128)   73856     \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_20 (TimeD  (None, 18, 12, 12, 128)   512       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_21 (TimeD  (None, 18, 12, 12, 128)   0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_22 (TimeD  (None, 18, 12, 12, 128)   147584    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_23 (TimeD  (None, 18, 12, 12, 128)   512       \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_24 (TimeD  (None, 18, 12, 12, 128)   0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_25 (TimeD  (None, 18, 6, 6, 128)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_26 (TimeD  (None, 18, 6, 6, 128)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_27 (TimeD  (None, 18, 6, 6, 256)     295168    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_28 (TimeD  (None, 18, 6, 6, 256)     1024      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_29 (TimeD  (None, 18, 6, 6, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_30 (TimeD  (None, 18, 6, 6, 256)     590080    \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_31 (TimeD  (None, 18, 6, 6, 256)     1024      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_32 (TimeD  (None, 18, 6, 6, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_33 (TimeD  (None, 18, 3, 3, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_34 (TimeD  (None, 18, 3, 3, 256)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_35 (TimeD  (None, 18, 3, 3, 512)     1180160   \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_36 (TimeD  (None, 18, 3, 3, 512)     2048      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_37 (TimeD  (None, 18, 3, 3, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_38 (TimeD  (None, 18, 3, 3, 512)     2359808   \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_39 (TimeD  (None, 18, 3, 3, 512)     2048      \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_40 (TimeD  (None, 18, 3, 3, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_41 (TimeD  (None, 18, 1, 1, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_42 (TimeD  (None, 18, 1, 1, 512)     0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " time_distributed_43 (TimeD  (None, 18, 512)           0         \n",
            " istributed)                                                     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 18, 512)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512)               2099200   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6825765 (26.04 MB)\n",
            "Trainable params: 6821797 (26.02 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size)\n",
        "val_generator = generator(val_path, val_doc, batch_size)"
      ],
      "metadata": {
        "id": "YwS-ZSfnHOP0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Gesture_recog' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "\n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-model-epoch{epoch:05d}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 10,\n",
        "  verbose = 0, mode = \"auto\", epsilon = 1e-04, cooldown = 0,\n",
        "  min_lr = 0)\n",
        "callbacks_list = [checkpoint, LR]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dklDO22ZHQi8",
        "outputId": "f6c91812-44b8-4d84-e1cb-021bea3c99b0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ],
      "metadata": {
        "id": "sV6Nfc_yHdDj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history  = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "                    callbacks=callbacks_list, validation_data=val_generator,\n",
        "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLSvvUoBHfLe",
        "outputId": "86dbe8b8-a7fd-4b7a-8fc1-bc6febc93139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-0224b2e774ad>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history  = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source path =  /content/drive/MyDrive/Colab Notebooks/gesture_recognition/Project_data/train ; batch size = 51\n",
            "Epoch 1/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6180 - categorical_accuracy: 0.1905Source path =  /content/drive/MyDrive/Colab Notebooks/gesture_recognition/Project_data/val ; batch size = 51\n",
            "\n",
            "Epoch 1: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00001.h5\n",
            "13/13 [==============================] - 129s 7s/step - loss: 1.6180 - categorical_accuracy: 0.1905 - val_loss: 1.6069 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6145 - categorical_accuracy: 0.1538\n",
            "Epoch 2: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00002.h5\n",
            "13/13 [==============================] - 34s 3s/step - loss: 1.6145 - categorical_accuracy: 0.1538 - val_loss: 1.6530 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6185 - categorical_accuracy: 0.1538\n",
            "Epoch 3: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00003.h5\n",
            "13/13 [==============================] - 23s 2s/step - loss: 1.6185 - categorical_accuracy: 0.1538 - val_loss: 1.6074 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6170 - categorical_accuracy: 0.0769\n",
            "Epoch 4: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00004.h5\n",
            "13/13 [==============================] - 21s 2s/step - loss: 1.6170 - categorical_accuracy: 0.0769 - val_loss: 1.5946 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5978 - categorical_accuracy: 0.3846\n",
            "Epoch 5: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00005.h5\n",
            "13/13 [==============================] - 38s 3s/step - loss: 1.5978 - categorical_accuracy: 0.3846 - val_loss: 1.5288 - val_categorical_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.5982 - categorical_accuracy: 0.0769\n",
            "Epoch 6: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00006.h5\n",
            "13/13 [==============================] - 12s 914ms/step - loss: 1.5982 - categorical_accuracy: 0.0769 - val_loss: 1.6437 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6347 - categorical_accuracy: 0.2692\n",
            "Epoch 7: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00007.h5\n",
            "13/13 [==============================] - 50s 4s/step - loss: 1.6347 - categorical_accuracy: 0.2692 - val_loss: 1.6602 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.6046 - categorical_accuracy: 0.2692\n",
            "Epoch 8: saving model to Gesture_recog_2024-03-0510_55_43.403566/model-model-epoch00008.h5\n",
            "13/13 [==============================] - 42s 3s/step - loss: 1.6046 - categorical_accuracy: 0.2692 - val_loss: 1.5793 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 9/15\n",
            " 4/13 [========>.....................] - ETA: 22s - loss: 1.6276 - categorical_accuracy: 0.0000e+00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiKmHXY6ODLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "UDTK0VqoMkDp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(20,6))\n",
        "# ax1 = plt.subplot(121)\n",
        "# ax1 = plt.plot(history.history['loss'])\n",
        "# ax1 = plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='lower left')\n",
        "# ax2 = plt.subplot(122)\n",
        "# ax2 = plt.plot(history.history['categorical_accuracy'])\n",
        "# ax2 = plt.plot(history.history['val_categorical_accuracy'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('categorical_accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='lower left')"
      ],
      "metadata": {
        "id": "aaYeKKruIYAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZZnjQtndO3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M6zygfdSZhx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}